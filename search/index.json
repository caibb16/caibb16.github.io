[{"content":"绪论 误差 绝对误差： $e = x^* - x$\n$|e| = |x^* - x| \\leq \\varepsilon$，$\\varepsilon$ 为近似值 $x$ 的绝对误差限\n相对误差： $e_r = \\frac{e}{x}$\n$|e_r| = \\frac{|e|}{|x|} \\leq \\varepsilon_r$，$\\varepsilon_r$ 为近似值 $x$ 的相对误差限\n有效数：如果 $|x^* - x| \\leq \\frac{1}{2} \\times 10^{-t}$，则近似值 $x$ 的有效数字为 $n$ 位，$n = t + $ 小数点前的有效数字位数\n数据误差对函数的影响：\n若 $y = f(x_1, x_2)$，则误差传播可用泰勒展开近似表示，即\n$$ e(y) \\approx \\frac{\\partial f(x_1, x_2)}{\\partial x_1} e(x_1) + \\frac{\\partial f(x_1, x_2)}{\\partial x_2} e(x_2) $$$$ e_r(y) = \\frac{e(y)}{y} \\approx \\frac{\\partial f}{\\partial x_1} \\frac{x_1}{f(x_1, x_2)} e_r(x_1) + \\frac{\\partial f}{\\partial x_2} \\frac{x_2}{f(x_1, x_2)} e_r(x_2) $$补充： 二元函数泰勒展开：\n$$ f(x_1 + \\Delta x_1, x_2 + \\Delta x_2) = f(x_1, x_2) + \\frac{\\partial f}{\\partial x_1} \\Delta x_1 + \\frac{\\partial f}{\\partial x_2} \\Delta x_2 \\newline + \\frac{1}{2!} \\left( \\frac{\\partial^2 f}{\\partial x_1^2} (\\Delta x_1)^2 + 2 \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} \\Delta x_1 \\Delta x_2 + \\frac{\\partial^2 f}{\\partial x_2^2} (\\Delta x_2)^2 \\right) + \\cdots $$方程求根 $f(x) = 0$ 迭代法的收敛性 设迭代格式为 $x_{k+1} = \\varphi(x_k)$，若存在 $x^ *$ 使得 $x^ *= \\varphi(x^ * )$，则 $x^ *$ 为方程 $f(x) = 0$ 的一个根。\n迭代法收敛定理：\n设 $\\varphi(x)$ 在 $[a, b]$ 上存在一阶连续导数，且满足：\n对任意 $x \\in [a, b]$，有 $\\varphi(x) \\in [a, b]$ 存在 $0 \u0026lt; L \u0026lt; 1$，使得对任意 $x \\in [a, b]$，有 $\\max\\limits_{a \\leq x \\leq b} |\\varphi\u0026rsquo;(x)| \\leq L \u0026lt; 1$ 则\n$x = \\varphi(x)$ 在 $[a, b]$ 上有唯一实根 $x^ *$ 对任意初值 $x_0 \\in [a, b]$，迭代格式 $x_{k+1} = \\varphi(x_k)$ 收敛于 $x^ *$，且有 $$ |x_k - x^*| \\leq \\frac{L}{1-L} |x_k - x_{k-1}|,\\quad k = 1, 2, \\cdots; $$$$ |x_k - x^*| \\leq \\frac{L^k}{1-L} |x_1 - x_0|,\\quad k = 1, 2, \\cdots; $$$$ \\lim_{k \\to \\infty} \\frac{x^* - x_{k+1}}{x^* - x_k} = \\varphi'(x^*) $$ 设方程 $x = \\varphi(x)$ 在区间 $[a, b]$ 上有根，且 $\\min\\limits_{a \\leq x \\leq b} |\\varphi\u0026rsquo;(x)| \\geq 1$，则对任意 $x_0 \\in [a, b]$，且 $x_0 \\neq x^*$，迭代格式 $x_{k+1} = \\varphi(x_k)$ 发散。 Newton 迭代法 设 $f(x)$ 在区间 $[a, b]$ 上连续，且 $f(a) f(b) \u0026lt; 0$，则存在 \\(x^* \\in (a, b)\\) 使得 $f(x^*) = 0$。 取初值 $x_0 \\in [a, b]$，则迭代公式为\n$$ x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)} $$Newton 迭代的局部收敛性 若 $\\varphi(x)$ 在 \\(x^*\\) 附近的某个邻域内有 $p (\\geq 1)$ 阶连续导数，且\n$$ \\varphi'(x^*) = \\varphi''(x^*) = \\cdots = \\varphi^{(p-1)}(x^*) = 0, \\quad \\varphi^{(p)}(x^*) \\neq 0 $$则迭代格式在 \\(x^*\\) 附近为 $p$ 阶局部收敛，且有\n$$ \\lim_{k \\to \\infty} \\frac{x^* - x_{k+1}}{(x^* - x_k)^p} = (-1)^{p-1} \\frac{\\varphi^{(p)}(x^*)}{p!} $$设 \\(x^*\\) 是方程 $f(x) = 0$ 的 $m$ 重根，则 $$ \\varphi'(x^*) = 1 - \\frac{1}{m} $$ 当 $m = 1$，即 \\(x^*\\) 为方程单根时，$\\varphi\u0026rsquo;(x^*) = 0$，Newton 迭代至少二阶局部收敛。 当 $m \\geq 2$，即 \\(x^*\\) 为方程 $m (m \\geq 2)$ 重根时，$|\\varphi\u0026rsquo;(x^*)| \u0026lt; 1$，Newton 迭代一阶（线性）局部收敛。 补充： $$ \\lim_{k \\to \\infty} \\frac{x^* - x_{k+1}}{(x^* - x_k)^2} = -\\frac{f''(x^*)}{2 f'(x^*)} $$重根的 Newton 迭代法 设 \\(x^*\\) 是方程 $f(x) = 0$ 的 $m$ 重根\n若 $m$ 已知，迭代改为： $$ x_{k+1} = x_k - m \\frac{f(x_k)}{f'(x_k)},\\quad k = 0, 1, \\cdots. $$ 若 $m$ 未知，记 $u(x) = \\frac{f(x)}{f\u0026rsquo;(x)}$，此时 \\(x^*\\) 是方程 $u(x) = 0$ 的单根，迭代改为： $$ x_{k+1} = x_k - \\frac{u(x_k)}{u'(x_k)},\\quad k = 0, 1, \\cdots. $$线性方程组的数值解法 三角形方程组的回代法 设线性方程组 $Ax = b$ 已化为上三角形形式： $$ \\begin{cases} a_{11} x_1 + a_{12} x_2 + \\cdots + a_{1n} x_n = b_1 \\\\ \\quad \\quad \\quad \\vdots \\\\ 0 \\quad + 0 \\quad + \\cdots + a_{nn} x_n = b_n \\end{cases} $$ 则回代法求解步骤为：\n计算 $x_n = \\frac{b_n}{a_{nn}}$ 对 $k = n-1, n-2, \\cdots, 1$，依次计算 $$ x_k = \\frac{b_k - \\sum\\limits_{j=k+1}^{n} a_{kj} x_j}{a_{kk}} $$ 列主元高斯消去法 在第 k 步消元之前, 从第 k 列位于对角线以下的元素中选绝对值最大者作为主元,然后进行消元。 使用回代法求解上三角形方程组 $Ux = y$，其中 $U$ 为消元后的系数矩阵，$y$ 为更新后的常数向量。 三对角方程组的追赶法 设三对角方程组为： $$ \\begin{bmatrix} b_1 \u0026 c_1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\ a_2 \u0026 b_2 \u0026 c_2 \u0026 \\cdots \u0026 0 \\\\ 0 \u0026 a_3 \u0026 b_3 \u0026 \\cdots \u0026 0 \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ 0 \u0026 0 \u0026 0 \u0026 a_n \u0026 b_n \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\vdots \\\\ x_n \\end{bmatrix}= \\begin{bmatrix} d_1 \\\\ d_2 \\\\ d_3 \\\\ \\vdots \\\\ d_n \\end{bmatrix} $$ 则追赶法求解步骤为：\n消元过程： $$ \\begin{cases} \\beta_1 = b_1, y_1 = d_1 \\\\ l_i = \\frac{a_i}{\\beta_{i-1}}, \\quad \\beta_i = b_i - l_i c_{i-1}, \\quad y_i = d_i - l_i y_{i-1} \\quad i = 2, 3, \\cdots, n \\end{cases} $$ 回代过程：\n得到同解三角方程组为 $$ \\begin{bmatrix} \\beta_1 \u0026 c_1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\ 0 \u0026 \\beta_2 \u0026 c_2 \u0026 \\cdots \u0026 0 \\\\ 0 \u0026 0 \u0026 \\beta_3 \u0026 \\cdots \u0026 0 \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ 0 \u0026 0 \u0026 0 \u0026 0 \u0026 \\beta_n \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\vdots \\\\ x_n \\end{bmatrix}= \\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_n \\end{bmatrix} $$ 计算 $$ \\begin{cases} x_n = \\frac{y_n}{\\beta_n} \\\\ x_i = \\frac{y_i - c_i x_{i+1}}{\\beta_i} \\quad i = n-1, n-2, \\cdots, 1 \\end{cases} $$ 向量范数 定义：非负性、齐次性、三角不等式 常用向量范数： $L_1$ 范数：$||x||_ 1 = \\sum\\limits_{i=1}^{n} |x_i|$ $L_{\\infty}$ 范数：$||x||_ {\\infty} = \\max\\limits_{1 \\leq i \\leq n} |x_i|$ $L_2$ 范数：$||x||_ 2 =\\sqrt{ \\sum\\limits_{i=1}^{n} |x_i|^2 }$ 矩阵范数 算子范数：$||A|| = \\max\\limits_{x \\neq 0} \\frac{||Ax||}{||x||}$\n谱半径：$\\rho(A) = \\max\\limits_{1 \\leq i \\leq n} |\\lambda_i|$，其中 $\\lambda_i$ 为矩阵 $A$ 的特征值\n常用矩阵范数：\n$L_1$ 范数：$||A||_ 1 = \\max\\limits_{1 \\leq j \\leq n} \\sum\\limits_{i=1}^{n} |a_{ij}| \\quad$ 按列求和的最大值 $L_{\\infty}$ 范数：$||A||_ {\\infty} = \\max\\limits_{1 \\leq i \\leq n} \\sum\\limits_{j=1}^{n} |a_{ij}| \\quad$ 按行求和的最大值 $L_2$ 范数：$||A||_ 2 = \\sqrt{\\rho(A^T A)}$ 条件数：$cond(A) = ||A|| \\cdot ||A^{-1}||$\n谱半径与2范数的关系：$\\rho(A) \\leq ||A||_ 2$\n如果 $A$ 是对称矩阵，则 $\\rho(A) = ||A||_ 2$\n迭代法求解线性方程组 将线性方程组 Ax = b 写为分量形式： $$ \\begin{cases} a_{11} x_1 + a_{12} x_2 + \\cdots + a_{1n} x_n = b_1 \\\\ a_{21} x_1 + a_{22} x_2 + \\cdots + a_{2n} x_n = b_2 \\\\ \\quad \\quad \\quad \\vdots \\\\ a_{n1} x_1 + a_{n2} x_2 + \\cdots + a_{nn} x_n = b_n \\end{cases} $$ 从第 $i$ 个方程中解出 $x_i$，得到如下同解方程组： $$ \\begin{cases} x_1 = (b_1-a_{12}x_2-a_{13} x_3 \\cdots - a_{1n} x_n)/a_{11} \\\\ x_2 = (b_2 - a_{21} x_1 - a_{23} x_3 - \\cdots - a_{2n} x_n)/a_{22} \\\\ \\quad \\quad \\quad \\vdots \\\\ x_n = (b_n - a_{n1} x_1 - a_{n2} x_2 - \\cdots - a_{n,n-1} x_{n-1})/a_{nn} \\end{cases} $$ Jacobi 迭代格式： $$ \\begin{cases} x_1^{(k+1)} = (b_1 - a_{12} x_2^{(k)} - a_{13} x_3^{(k)} - \\cdots - a_{1n} x_n^{(k)})/a_{11} \\\\ x_2^{(k+1)} = (b_2 - a_{21} x_1^{(k)} - a_{23} x_3^{(k)} - \\cdots - a_{2n} x_n^{(k)})/a_{22} \\\\ \\quad \\quad \\quad \\vdots \\\\ x_n^{(k+1)} = (b_n - a_{n1} x_1^{(k)} - a_{n2} x_2^{(k)} - \\cdots - a_{n,n-1} x_{n-1}^{(k)})/a_{nn} \\end{cases} $$ Gauss-Seidel 迭代格式：\n用新分量替换旧分量 $$ \\begin{cases} x_1^{(k+1)} = (b_1 - a_{12} x_2^{(k)} - a_{13} x_3^{(k)} - \\cdots - a_{1n} x_n^{(k)})/a_{11} \\\\ x_2^{(k+1)} = (b_2 - a_{21} x_1^{(k+1)} - a_{23} x_3^{(k)} - \\cdots - a_{2n} x_n^{(k)})/a_{22} \\\\ \\quad \\quad \\quad \\vdots \\\\ x_n^{(k+1)} = (b_n - a_{n1} x_1^{(k+1)} - a_{n2} x_2^{(k+1)} - \\cdots - a_{n,n-1} x_{n-1}^{(k+1)})/a_{nn} \\end{cases} $$ SOR 迭代格式：\n第k+1次迭代近似值和第k次迭代近似值的加权平均 $$ \\begin{cases} x_1^{(k+1)} = (1-\\omega) x_1^{(k)} + \\omega (b_1 - a_{12} x_2^{(k)} - a_{13} x_3^{(k)} - \\cdots - a_{1n} x_n^{(k)}) /a_{11} \\\\ x_2^{(k+1)} = (1-\\omega) x_2^{(k)} + \\omega (b_2 - a_{21} x_1^{(k+1)} - a_{23} x_3^{(k)} - \\cdots - a_{2n} x_n^{(k)}) /a_{22} \\\\ \\quad \\quad \\quad \\vdots \\\\ x_n^{(k+1)} = (1-\\omega) x_n^{(k)} + \\omega (b_n - a_{n1} x_1^{(k+1)} - a_{n2} x_2^{(k+1)} - \\cdots - a_{n,n-1} x_{n-1}^{(k+1)}) /a_{nn} \\end{cases} $$ 迭代格式的收敛性 迭代格式收敛的充分必要条件：迭代矩阵 $B$ 的谱半径 $\\rho(B) \u0026lt; 1$ Jacobi 迭代格式的收敛性: 谱半径判断：迭代矩阵特征方程为 $|\\lambda D+L+U| = 0$ (系数矩阵的对角线乘 $\\lambda$ ) 充分条件判断：如果系数矩阵 $A$ 严格对角占优，则 Jacobi 迭代格式收敛。 Gauss-Seidel 迭代格式的收敛性: 谱半径判断：迭代矩阵特征方程为 $|\\lambda (D+L)+U| = 0$ (系数矩阵的下三角乘 $\\lambda$ ) 充分条件判断：如果系数矩阵 $A$ 严格对角占优，则 Gauss-Seidel 迭代格式收敛。 SOR 迭代格式的收敛性: 收敛的必要条件：$0 \u0026lt; \\omega \u0026lt; 2$ 多项式插值 拉格朗日插值多项式 定义：设插值节点为 $x_0, x_1, \\cdots, x_n$，对应的函数值为 $f(x_0), f(x_1), \\cdots, f(x_n)$，若存在一个次数不超过 $n$ 的多项式 $p_n(x)$，使得 $$p_n(x_i) = f(x_i), \\quad i = 0, 1, \\cdots, n$$ 成立，则称 $p_n(x)$ 为函数 $f(x)$ 的 $n$ 次插值多项式。\n定理：满足上述条件的 $n$ 次多项式 $p_n(x)$ 存在且唯一。\n基本插值多项式：定义 $n+1$ 个基本插值多项式 $l_k(x)$，满足 $$ l_k(x_j) = \\begin{cases}1, \u0026 j = k \\\\ 0, \u0026 j \\neq k \\end{cases} $$ 则 $l_k(x)$ 可表示为： $$ l_k(x) = \\prod\\limits_{ \\substack{i=0 \\\\ i \\neq k}}^{n} \\frac{x - x_i}{x_k - x_i} $$ 利用基本插值多项式， $n$ 次 Lagrange 插值多项式为： $$ L_n(x) = \\sum\\limits_{k=0}^{n} f(x_k) l_k(x)= \\sum\\limits_{k=0}^{n} f(x_k) \\prod\\limits_{ \\substack{i=0 \\\\ i \\neq k}}^{n} \\frac{x - x_i}{x_k - x_i} $$ $l_0(x), l_1(x), \\cdots, l_n(x)$ 线性无关，称为 $n$ 次 Lagrange 插值基函数。\n插值余项及误差估计：若函数 $f(x)$ 在区间 $[a, b]$ 上具有 $n+1$ 阶连续导数，则对任意 $x \\in [a, b]$，存在 $\\xi \\in (a, b)$，使得 $$ R_n(x)=f(x) - L_n(x) = \\frac{f^{(n+1)}(\\xi)}{(n+1)!} \\omega_{n+1}(x) $$ 其中 $\\omega_{n+1}(x) = (x - x_0)(x - x_1) \\cdots (x - x_n)$。\nNewton 插值多项式 差商的定义： $$ f[x_i] = f(x_i) $$ $$ f[x_i, x_{i+1}, \\cdots, x_{i+k}] = \\frac{f[x_{i+1}, \\cdots, x_{i+k}] - f[x_i, \\cdots, x_{i+k-1}]}{x_{i+k} - x_i} $$ $n$ 次 Newton 插值多项式定义为： $$ L_n(x) = f[x_0] + f[x_0, x_1](x - x_0) + f[x_0, x_1, x_2](x - x_0)(x - x_1) \\\\+ \\cdots + f[x_0, x_1, \\cdots, x_n](x - x_0)(x - x_1) \\cdots (x - x_{n-1}) $$ $k$ 阶差商与 $k$ 阶导数的关系： $$ f[x_0, x_1, \\cdots, x_k] = \\frac{f^{(k)}(\\eta)}{k!}, \\quad \\eta \\in (\\min(x_0, \\cdots, x_k), \\max(x_0, \\cdots, x_k)) $$ Hermite 插值多项式 定义：给定$n+1$ 个互异节点 $x_0, x_1, \\cdots, x_n$上的函数值和直到$m_i$阶的导数值，令 $m = \\sum \\limits_0^n(m_i+1)-1$， 若存在一个次数不超过 $m$ 的多项式 $H_m(x)$，使得 $$ \\begin{cases} H_m^{(j)}(x_i) = f^{(j)}(x_i), \\quad j = 0, 1, \\cdots, m_i \\\\ i = 0, 1, \\cdots, n \\end{cases} $$ 则称 $H_m(x)$ 为函数 $f(x)$ 的 Hermite 插值多项式。\n重节点插值：将上述插值问题看成是在 $m + 1$ 不同节点上的 Newton 插值, 然后取极限就成为 $n + 1$ 不同节点上的 Hermite 插值, 称之为重节点插值。\n$m$次 Hermite 插值多项式为： $$ H_m(x) = f[x_0] + f[x_0, x_0](x - x_0) + f[x_0, x_0, x_1](x - x_0)^2 \\\\+ \\cdots + f[\\underbrace{x_0, x_0, \\cdots, x_0}_{m_0+1}, \\underbrace{x_1, x_1, \\cdots, x_1}_{m_1+1}, \\cdots, \\underbrace{x_n, x_n, \\cdots, x_n}_{m_n+1}](x - x_0)^{m_0+1}(x - x_1)^{m_1+1} \\cdots (x - x_n)^{m_n} $$ 重节点差商公式： $$ f[\\underbrace{x_i, x_i, \\cdots, x_i}_{k+1}] = \\frac{f^{(k)}(x_i)}{k!} \\\\ f[x_0, x_0,x_1] = \\frac{f[x_0, x_1] - f[x_0, x_0]}{x_1 - x_0} $$ 插值余项为： $$ R_m(x) = f(x) - H_m(x) = \\frac{f^{(m+1)}(\\xi)}{(m+1)!} (x - x_0)^{m_0+1}(x - x_1)^{m_1+1} \\cdots (x - x_n)^{m_n+1} $$3次样条插值函数 定义：每段小区间上用3次多项式进行插值，且在区间上具有连续二阶导数，称为3次样条插值函数。\n要求3次样条插值函数 $S(x)$，每个小区间要确定4个参数，共要确定 $4n$ 个参数。\n在每个节点处满足下面的连续性条件:\n$S(x_j-0) = S(x_j+0),\\quad S\u0026rsquo;(x_j-0) = S\u0026rsquo;(x_j+0),\\quad S\u0026rsquo;\u0026rsquo;(x_j-0) = S\u0026rsquo;\u0026rsquo;(x_j+0), \\quad j = 1, 2, \\cdots, n-1$\n共有 $3(n-1)$ 个条件，加上$n+1$ 个插值条件，共有 $4n - 2$ 个条件，还要加上2个条件，才能确定 $4n$ 个参数。\n常用的附加条件有： (边界条件) 已知两端点的一阶导数, 即 $S\u0026rsquo;(x_0) = f\u0026rsquo;(x_0), \\quad S\u0026rsquo;(x_n) = f\u0026rsquo;(x_n)$ (边界条件) 已知两端点的二阶导数, 即 $S\u0026rsquo;\u0026rsquo;(x_0) = f\u0026rsquo;\u0026rsquo;(x_0), \\quad S\u0026rsquo;\u0026rsquo;(x_n) = f\u0026rsquo;\u0026rsquo;(x_n)$ 若令 $S\u0026rsquo;\u0026rsquo;(x_0) = 0, \\quad S\u0026rsquo;\u0026rsquo;(x_n) = 0$，则称为自然边界条件。 (连接条件) 要求 $S\u0026rsquo;\u0026rsquo;\u0026rsquo;(x)$ 在 $x_1$ 和 $x_{n-1}$ 处连续，即 $S\u0026rsquo;\u0026rsquo;\u0026rsquo;(x_1-0) = S\u0026rsquo;\u0026rsquo;\u0026rsquo;(x_1+0), \\quad S\u0026rsquo;\u0026rsquo;\u0026rsquo;(x_{n-1}-0) = S\u0026rsquo;\u0026rsquo;\u0026rsquo;(x_{n-1}+0)$ 求法： $S(x)=y_j+{f[x_j,x_{j+1}]-(\\frac{1}{3}M_j+\\frac{1}{6}M_{j+1})h_j}(x-x_j)+ \\frac{M_j}{2}(x - x_j)^2 + \\frac{M_{j+1} - M_j}{6h_j}(x - x_j)^3, \\quad x \\in [x_j, x_{j+1}]，j=0,1,⋯,n-1$\n其中 $h_j = x_{j+1} - x_j$，$M_j = S\u0026rsquo;\u0026rsquo;(x_j)$\n对于边界条件 $S\u0026rsquo;(x_0) = f\u0026rsquo;(x_0), \\quad S\u0026rsquo;(x_n) = f\u0026rsquo;(x_n)$，可列出如下方程组求解 $M_j$： $$\\begin{bmatrix} 2 \u0026 1 \\\\ \\mu_1 \u0026 2 \u0026 \\lambda_1 \\\\ \u0026 \\mu_2 \u0026 2 \u0026 \\lambda_2 \\\\ \u0026 \u0026 \\ddots \u0026 \\ddots \u0026 \\ddots \\\\ \u0026 \u0026 \u0026 \\mu_{n-1} \u0026 2 \u0026 \\lambda_{n-1} \\\\ \u0026 \u0026 \u0026 \u0026 1 \u0026 2 \\end{bmatrix} \\begin{bmatrix} M_0 \\\\ M_1 \\\\ M_2 \\\\ \\vdots \\\\ M_{n-1} \\\\ M_n \\end{bmatrix} = \\begin{bmatrix} d_0 \\\\ d_1 \\\\ d_2 \\\\ \\vdots \\\\ d_{n-1} \\\\ d_n \\end{bmatrix} $$ 对于边界条件 $S\u0026rsquo;\u0026rsquo;(x_0) = f\u0026rsquo;\u0026rsquo;(x_0), \\quad S\u0026rsquo;\u0026rsquo;(x_n) = f\u0026rsquo;\u0026rsquo;(x_n)$，可列出如下方程组求解 $M_j$： $$\\begin{bmatrix} 2 \u0026 \\lambda_1 \\\\ \\mu_2 \u0026 2 \u0026 \\lambda_2 \\\\ \u0026 \\mu_3 \u0026 2 \u0026 \\lambda_3 \\\\ \u0026 \u0026 \\ddots \u0026 \\ddots \u0026 \\ddots \\\\ \u0026 \u0026 \u0026 \\mu_{n-2} \u0026 2 \u0026 \\lambda_{n-2} \\\\ \u0026 \u0026 \u0026 \u0026 \\mu_{n-1} \u0026 2 \\end{bmatrix} \\begin{bmatrix} M_1 \\\\ M_2 \\\\ M_3 \\\\ \\vdots \\\\ M_{n-2} \\\\ M_{n-1} \\end{bmatrix} = \\begin{bmatrix} d_1-\\mu_1 f''(x_0) \\\\ d_2 \\\\ d_3 \\\\ \\vdots \\\\ d_{n-2} \\\\ d_{n-1}-\\lambda_{n-1} f''(x_n) \\end{bmatrix} $$ 其中 $$\\mu_j = \\frac{h_{j-1}}{h_{j-1} + h_j}, \\quad \\lambda_j = \\frac{h_j}{h_{j-1} + h_j}=1-\\mu_j, \\quad j = 1, 2, \\cdots, n-1$$ $$d_0 = 6f[x_0,x_0,x_1], \\quad d_n = 6f[x_{n-1},x_n,x_n]$$ $$d_j = 6 \\left( f[x_{j-1}, x_j, x_{j+1}] \\right), \\quad j = 1, 2, \\cdots, n-1$$多项式逼近 最佳一致逼近 连续函数的范数：设$f\\in C[a,b]$，记 $$ ||f||_1 = \\int_a^b |f(x)| dx,\\quad ||f||_{\\infty} = \\max_{a \\leq x \\leq b} |f(x)|,\\quad ||f||_2 = \\sqrt{ \\int_a^b |f(x)|^2 dx } $$ 最佳一致逼近多项式\n定义：设 $f(x) \\in C[a,b]$，$M_n$ 为次数不超过 $n$ 的任意多项式集合，若$\\exists p_n\\in M_n$，使得对任意 $q_n \\in M_n$，有 $$||f - p_n||_{\\infty} \\leq ||f - q_n||_{\\infty}$$ 则称 $p_n(x)$ 为函数 $f(x)$ 在区间 $[a,b]$ 上的$n$次最佳一致逼近多项式。 一次最佳一致逼近多项式求法：\n设 $p_1(x) = c_0 + c_1 x$，若 $f\u0026rsquo;\u0026rsquo;(x)$ 在 $(a, b)$ 内存在且保号，则 $f(x) − p_1 (x)$ 在 [a, b] 内有 3 个交错偏差点 $a, x_1 , b$, 于是可得 $$\\begin{cases} f(a) - p_1(a) = -[f(x_1)-p_1(x_1)] = f(b)-p_1(b) \\\\ f'(x_1) - p_1'(x_1) = 0 \\end{cases}$$ 最佳平方逼近多项式\n定义：设$X$为内积空间， $f \\in X$，$M$ 为$X$的子空间，$\\varphi_0,\\varphi_1,\\cdots,\\varphi_m$为$M$的一组基，若$\\exists \\varphi\\in M_n$，使得对任意 $\\psi \\in M$，有 $$||f - \\varphi|| \\leq ||f - \\psi||$$ 则称 $ \\varphi$ 是 $f$ 在 $M$ 中的最佳平方逼近元 最佳平方逼近多项式求法：\n如果$\\varphi_i(x)=x^i(i=0,1,\\cdots,m)$，设 $p(x) = \\sum\\limits_{i=0}^{m} c_i \\varphi_i(x)$，则 $p(x)$ 称为 $f(x)$ 在 $[a, b]$ 上的 $m$ 次最佳平方逼近多项式\n$c_0 , c_1 , \\cdots , c_m$ 是下面的 (正规) 方程组的解: $$\\begin{bmatrix} (\\varphi_0, \\varphi_0) \u0026 (\\varphi_0, \\varphi_1) \u0026 \\cdots \u0026 (\\varphi_0, \\varphi_m) \\\\ (\\varphi_1, \\varphi_0) \u0026 (\\varphi_1, \\varphi_1) \u0026 \\cdots \u0026 (\\varphi_1, \\varphi_m) \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ (\\varphi_m, \\varphi_0) \u0026 (\\varphi_m, \\varphi_1) \u0026 \\cdots \u0026 (\\varphi_m, \\varphi_m) \\end{bmatrix} \\begin{bmatrix} c_0 \\\\ c_1 \\\\ \\vdots \\\\ c_m \\end{bmatrix} = \\begin{bmatrix} (f, \\varphi_0) \\\\ (f, \\varphi_1) \\\\ \\vdots \\\\ (f, \\varphi_m) \\end{bmatrix}$$ 其中 $(f, g) = \\int_a^b f(x) g(x) dx$ 为内积。 超定方程组的最小二乘解：\n设超定方程组为 $Ax = b$，其中 $A$ 为 $m \\times n$ 矩阵，$m \u0026gt; n$，则其最小二乘解 $x^*$ 满足正规方程组 $$A^T A x = A^T b$$ 离散数据的最佳平方逼近多项式：\n给定离散数据点 $(x_i, y_i), i = 0, 1, \\cdots, n$，设 $p(x) = \\sum\\limits_{i=0}^{m} c_i \\varphi_i(x)$，如果$\\varphi_k(x)=x^k$，则 $p(x)$ 称为数据点的 $m$ 次最小二乘拟合多项式。 记 $$ \\mathbf{\\varphi}_k = \\begin{bmatrix} \\varphi_k(x_0) \\\\ \\varphi_k(x_1) \\\\ \\vdots \\\\ \\varphi_k(x_n) \\end{bmatrix}, \\quad \\mathbf{y} = \\begin{bmatrix} y_0 \\\\ y_1 \\\\ \\vdots \\\\ y_n \\end{bmatrix} $$\n$c_0 , c_1 , \\cdots , c_n$ 是下面的 (正规) 方程组的解: $$\\begin{bmatrix} (\\varphi_0, \\varphi_0) \u0026 (\\varphi_0, \\varphi_1) \u0026 \\cdots \u0026 (\\varphi_0, \\varphi_m) \\\\ (\\varphi_1, \\varphi_0) \u0026 (\\varphi_1, \\varphi_1) \u0026 \\cdots \u0026 (\\varphi_1, \\varphi_m) \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ (\\varphi_m, \\varphi_0) \u0026 (\\varphi_m, \\varphi_1) \u0026 \\cdots \u0026 (\\varphi_m, \\varphi_m) \\end{bmatrix} \\begin{bmatrix} c_0 \\\\ c_1 \\\\ \\vdots \\\\ c_m \\end{bmatrix} = \\begin{bmatrix} (y, \\varphi_0) \\\\ (y, \\varphi_1) \\\\ \\vdots \\\\ (y, \\varphi_m) \\end{bmatrix}$$ 数值积分与数值微分 插值型求积公式 定义\n设有计算定积分 $I(f) = \\int_a^b f(x) dx$ 的求积公式 $$I_n(f) = \\sum\\limits_{k=0}^{n} A_k f(x_k)$$ 如果求积系数 $A_k=\\int_a^b l_k(x) dx$，其中 $l_k(x)$ 为插值节点上的 Lagrange 基函数，则称 $I_n(f)$ 为插值型求积公式。\n截断误差为： $$R_n(f) = I(f) - I_n(f) = \\int_a^b \\frac{f^{(n+1)}(\\xi)}{(n+1)!} \\prod_{i=0}^n (x - x_i) dx, \\quad \\xi \\in (a, b)$$ 若函数 $f(x)$ 在 如果求积节点 $x_k$ 为等距节点，即 $$x_k = a + k h, \\quad h = \\frac{b-a}{n}, \\quad k = 0, 1, \\cdots, n$$ 则称为 Newton-Cotes 求积公式，可写为： $$I_n(f) = (b-a) \\sum\\limits_{k=0}^{n} C_{n,k} f(x_k)$$ 2. 常用的等距节点插值型求积公式\n* 梯形公式（n=1）：\n$$T(f) = \\frac{b-a}{2} [f(a) + f(b)]$$ * Simpson 公式（n=2）：\n$$S(f) = \\frac{b-a}{6} [f(a) + 4f\\left(\\frac{a+b}{2}\\right) + f(b)]$$ 3. 代数精度\n定义：设求积公式 $I_n(f)$ 对任意次数不超过 $m$ 的多项式均精确成立，即 $$I(f) = I_n(f), \\quad \\forall f \\in P_m$$ 而至少对一个 $m+1$ 次多项式不精确成立，则称求积公式 $I_n(f)$ 的代数精度为 $m$ 定理： 求积公式 $I_n(f)$ 的代数精度至少为 $n$ $\\Leftrightarrow$ 该求积公式是插值型求积公式 求积公式 $I_n(f)$ 的代数精度为$m$ $\\Leftrightarrow$ 求积公式对 $1,x,x^2,\\cdots,x^m$ 均精确成立，而对 $x^{m+1}$ 不精确成立 截断误差表达式推导 梯形公式：$$R_T(f) = -\\frac{(b-a)^3}{12} f''(\\xi), \\quad \\xi \\in (a, b)$$ Simpson 公式：$$R_S(f) = -\\frac{(b-a)^5}{2880} f^{(4)}(\\xi), \\quad \\xi \\in (a, b)$$ 复化求积公式 定义\n将区间 $[a, b]$ 等分为 $n$ 个小区间，每个小区间上使用相同的求积公式进行积分近似，称为复化求积公式。\n记 $h = \\frac{b-a}{n},\\quad x_k = a + k h,\\quad k=0,1,\\cdots,n$，则复化求积公式可写为： $$I(f) = \\sum\\limits_{k=0}^{n-1} \\int_{x_k}^{x_{k+1}} f(x) dx$$ 复化梯形公式 $$T_n(f) = \\sum\\limits_{k=0}^{n-1} \\frac{h}{2} [f(x_k) + f(x_{k+1})]$$ 截断误差 $$I(f)-T_n(f) = -\\frac{b-a}{12}h^2 f''(\\eta), \\quad \\eta \\in (a, b)$$ $$I(f)-T_{2n}(f) \\approx \\frac{1}{3} [T_{2n}(f) - T_n(f)]$$ 递推关系式 $$T_{2n}(f) = \\frac{1}{2} [T_n(f) + h \\sum\\limits_{k=0}^{n-1} f\\left(x_{k+\\frac{1}{2}}\\right)]$$ 其中$x_{k+\\frac{1}{2}} = \\frac{x_k + x_{k+1}}{2}$为新增的n个节点, $h=\\frac{b-a}{n}$ 复化 Simpson 公式 $$S_n(f) = \\sum\\limits_{k=0}^{n-1} \\frac{h}{6} [f(x_{k}) + 4f(x_{k+\\frac{1}{2}}) + f(x_{k+1})]$$ 截断误差 $$I(f)-S_n(f) = -\\frac{b-a}{180}\\left(\\frac{h}{2}\\right)^4 f^{(4)}(\\eta), \\quad \\eta \\in (a, b)$$ $$I(f)-S_{2n}(f) \\approx \\frac{1}{15} [S_{2n}(f) - S_n(f)]$$ 复化求积公式的阶数 $$h\\rightarrow 0,\\quad I(f)-I_n(f) = O(h^p)$$ 则称复化求积公式的阶数为 $p$，由上文可知复化梯形公式为 2 阶, 复化 Simpson 公式为 4 阶 Romberg 求积方法 先利用复化梯形公式计算出一系列 $T_{2^k}(f)$，然后利用 $$S_n(f) \\approx \\frac{4}{3} T_{2n}(f) - \\frac{1}{3} T_n(f)$$ $$C_n(f) \\approx \\frac{16}{15} S_{2n}(f) - \\frac{1}{15} S_n(f)$$ $$R_n(f) \\approx \\frac{64}{63} C_{2n}(f) - \\frac{1}{63} C_n(f)$$ 依次递推，直到满足精度 $$I(f) - R_n(f) \\approx \\frac{1}{255} [R_{2n}(f) - R_{n}(f)] \u003c \\varepsilon$$Gauss 求积公式 定义：适当选择求积节点 $x_k$，使得求积公式的代数精度达到 $(2n+1)$，称为 Gauss 求积公式，对应的求积点 $x_k$ 称为 Gauss 点。 区间[-1,1] 上的 Gauss 求积公式 当 $n=0$ 时，1 点 Gauss 求积公式为： $$G_0(f) = 2 f(0)$$ 当 $n=1$ 时，2 点 Gauss 求积公式为： $$G_1(f) = f\\left(-\\frac{1}{\\sqrt{3}}\\right) + f\\left(\\frac{1}{\\sqrt{3}}\\right)$$ 当 $n=2$ 时，3 点 Gauss 求积公式为： $$G_2(f) = \\frac{5}{9} f\\left(-\\sqrt{\\frac{3}{5}}\\right) + \\frac{8}{9} f(0) + \\frac{5}{9} f\\left(\\sqrt{\\frac{3}{5}}\\right)$$ 区间[a,b] 上的 Gauss 求积公式\n考虑区间 $[a, b]$ 上的积分 $$\\int_a^b f(x) dx$$ 通过变量代换 $x = \\frac{a+b}{2} + \\frac{b-a}{2} t$ 将区间 $[a, b]$ 上的积分转化为区间 $[-1, 1]$ 上的积分，得到 $$\\int_a^b f(x) dx = \\frac{b-a}{2} \\int_{-1}^{1} f\\left(\\frac{a+b}{2} + \\frac{b-a}{2} t\\right) dt$$ 得到 Gauss 求积公式： $$I_n(f) = \\sum\\limits_{k=0}^{n}\\frac{b-a}{2} \\tilde{A_k} f\\left(\\frac{a+b}{2} + \\frac{b-a}{2} t_k\\right)$$ 再令$$x_k = \\frac{a+b}{2} + \\frac{b-a}{2} t_k,\\quad A_k = \\frac{b-a}{2} \\tilde{A_k}$$ 则有 $$I_n(f) = \\sum\\limits_{k=0}^{n} A_k f(x_k)$$ 截断误差表达式\nGauss 求积公式的截断误差为： $$R_n(f) = \\frac{f^{(2n+2)}(\\xi)}{(2n+2)!} \\int_a^b \\left[ \\prod_{k=0}^{n} (x - x_k) \\right]^2 dx, \\quad \\xi \\in (a, b)$$ 数值微分 差商代替导数值 $$向前差商：f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0)}{h}$$ $$向后差商：f'(x_0) \\approx \\frac{f(x_0) - f(x_0 - h)}{h}$$ $$中心差商：f'(x_0) \\approx \\frac{f(x_0 + h) - f(x_0 - h)}{2h}$$ 截断误差\n将 $f(x_0 + h), f(x_0 − h)$ 在 $x_0$ 点 Taylor 展开, 可以得 $$f'(x_0) - \\frac{f(x_0 + h) - f(x_0)}{h} = -\\frac{h}{2} f''(x_0)+O(h^2)$$ $$f'(x_0) - \\frac{f(x_0) - f(x_0 - h)}{h} = \\frac{h}{2} f''(x_0)+O(h^2)$$ $$f'(x_0) - \\frac{f(x_0 + h) - f(x_0 - h)}{2h} = -\\frac{h^2}{6} f^{(3)}(x_0)+O(h^3)$$ 插值型求导公式\n建立插值多项式 $p_n(x)$作为函数 $f(x)$ 的近似，取其导数 $p_n\u0026rsquo;(x)$ 作为 $f\u0026rsquo;(x)$ 的近似，称为插值型求导公式。\n常微分方程数值解 Euler 方法 Euler 公式： $$y_{i+1} = y_i + h f(x_i, y_i), \\quad i=0,1,\\cdots,n-1$$ 其中 $h$ 为步长，$y_i$ 为 $y(x_i)$ 的近似值。\n梯形公式： $$y_{i+1} = y_i + \\frac{h}{2} [f(x_i, y_i) + f(x_{i+1}, y_{i+1})], \\quad i=0,1,\\cdots,n-1$$ 预测校正公式(改进的Euler公式)： $$\\begin{cases} 预测：y^{(p)}_{i+1} = y_i + h f(x_i, y_i) \\\\ 校正：y_{i+1} = y_i + \\frac{h}{2} [f(x_i, y_i) + f(x_{i+1}, y^{(p)}_{i+1})] \\end{cases}$$ 局部截断误差：$R_{i+1} = y(x_{i+1}) - y(x_i) - \\frac{h}{2} [f(x_i, y(x_i)) + f(x_{i+1}, y(x_i)+hf(x_i,y(x_i))]$\n求法：分别求出预测公式的截断误差 $R^{（p）}_ {i+1}$ 和校正公式的截断误差 $R^{（c）}_ {i+1}$ ，则$R_{i+1}$可以通过加项减项凑出$R^{（p）}_ {i+1}$和$R^{（c）}_ {i+1}$\n若$R_{i+1}=O(h^{p+1})$，则称该公式为 $p$ 阶的。Euler 公式为 1 阶，梯形公式和预测校正公式为 2 阶。\n整体截断误差：$E(h)= \\max\\limits_{0 \\leq i \\leq n} |y(x_i) - y_i^{[h]}|$ Runge-Kutta 方法 r级 Runge-Kutta 公式： $$\\begin{cases} y_{i+1} = y_i + h \\sum\\limits_{j=1}^{r} \\alpha_j k_j \\\\ k_1 = f(x_i, y_i) \\\\ k_2 = f(x_i + \\lambda_2 h, y_i + h (\\mu_{21} k_1)) \\\\ k_3 = f(x_i + \\lambda_3 h, y_i + h (\\mu_{31} k_1 + \\mu_{32} k_2)) \\\\ \\quad \\vdots \\\\ k_r = f(x_i + \\lambda_j h, y_i + h (\\mu_{r1} k_1 + \\mu_{r2} k_2 + \\cdots + \\mu_{r,r-1} k_{r-1})) \\end{cases}$$ 2阶 Runge-Kutta 公式推导： 当 $r=2$ 时，有 $$\\begin{cases} y_{i+1} = y_i + h (\\alpha_1 k_1 + \\alpha_2 k_2) \\\\ k_1 = f(x_i, y_i) \\\\ k_2 = f(x_i + \\lambda_2 h, y_i + h \\mu_{21} k_1) \\end{cases}$$ 其局部截断误差为 $$\\begin{cases} R_{i+1} = y(x_{i+1}) - y(x_i) - h (\\alpha_1 K_1 + \\alpha_2 K_2) \\\\ K_1 = f(x_i, y(x_i)) \\\\ K_2 = f(x_i + \\lambda_2 h, y(x_i) + h \\mu_{21} K_1) \\end{cases}$$ 将 $y(x_{i+1})$ 在 $x_i$ 点 Taylor 展开, 将 $K_2$ 在 $(x_i, y_i)$ 点 Taylor 展开\n代入使公式具有二阶精度，即$R_{i+1}=O(h^{3})$，得 $$\\begin{cases} \\alpha_1 + \\alpha_2 = 1 \\\\ \\alpha_2 \\lambda_2 = \\frac{1}{2} \\\\ \\alpha_2 \\mu_{21} = \\frac{1}{2} \\end{cases}$$偏微分方程数值解 抛物型方程的差分解法 网格剖分 将求解区域 $[0, l] \\times [0, T]$ 作等距网格剖分，设空间步长为 $h = \\frac{l}{M}$，时间步长为 $\\tau = \\frac{T}{N}$，则网格点为 $$(x_i, t_k) = (i h, k \\tau), \\quad 0 \\leq i \\leq M, 0 \\leq k \\leq N$$ 记 $u_i^k$ 为 $u(x_i, t_k)$ 的近似值。$r = \\frac{a \\tau}{h^2}$ 为步长比。\n差分格式推导\n考虑下面的定解问题： $$\\frac{\\partial u}{\\partial t} - a \\frac{\\partial^2 u}{\\partial x^2}=f(x,t), \\quad a \u003e 0$$ $$u(x,0) = \\varphi(x), \\quad x \\in [0, l]$$ $$u(0,t) = \\alpha(t), \\quad u(l,t) = \\beta(t), \\quad t \\in [0, T]$$ 差分格式推导常用公式： $$g'(x_0)= \\frac{1}{h}[g(x_0+h)-g(x_0)] - \\frac{h}{2} g''(\\xi),\\quad x_0 \u003c \\xi \u003c x_0 + h;$$ $$g'(x_0)= \\frac{1}{h}[g(x_0)-g(x_0-h)] + \\frac{h}{2} g''(\\xi),\\quad x_0 - h \u003c \\xi \u003c x_0;$$ $$g'(x_0)= \\frac{1}{2h}[g(x_0+h)-g(x_0-h)] - \\frac{h^2}{6} g^{(3)}(\\xi),\\quad x_0 - h \u003c \\xi \u003c x_0 + h;$$ $$g''(x_0)= \\frac{1}{h^2}[g(x_0+h)-2g(x_0)+g(x_0-h)] - \\frac{h^2}{12} g^{(4)}(\\xi),\\quad x_0 - h \u003c \\xi \u003c x_0 + h;$$ $$g(x_0)= \\frac{1}{2}[g(x_0+h)+g(x_0-h)] - \\frac{h^2}{2} g''(\\xi),\\quad x_0 - h \u003c \\xi \u003c x_0 + h.$$ ","date":"2025-12-29T12:32:33+08:00","permalink":"https://caibb16.github.io/p/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E7%AC%94%E8%AE%B0/","title":"数值分析笔记"},{"content":"引言 本文尝试对Navila论文进行复现，引用如下：\nPaper Link\nProject Link\n论文解读 NaVILA: Legged Robot Vision-Language-Action Model for Navigation\n基本目标 在收到人类指令后，NaVILA 使用视觉语言模型处理 RGB 视频帧，并运用运动技能在机器人上执行任务。该机器人能够成功完成长时程导航任务，并在复杂环境中安全运行。\n该项目的创新基于端到端的VLA系统，该系统对通用 VLM 进行微调，以生成量化的低级动作，这个过程的推理和执行十分具有挑战性。本项目为了用更好的方式表示动作，建立了一个两级框架，将高层次的视觉语言理解与低层次的运动控制分开。\n两级框架 高层次视觉语言理解：VLM输出语言形式的中级动作，例如“右转 30 度”。中级动作输出传达了位置和方向信息，指导机器人的导航策略。 低层次运动控制：训练一个低级视觉运动策略来遵循指令以对导航指令进行执行，具体来说就是将VLM的高层语言导航指令转换为精确的联合动作。 实现方法 训练VLA用于导航 选择基于图像的视觉语言模型VILA 将历史和当前观测的标记与导航指令整合，构建导航任务提示 从人类视频中收集轨迹-指令对以增强在连续空间的导航能力 训练过程如下图：\n视觉移动策略 该控制策略在Isaac Sim模拟器中使用Isaac Lab进行训练，然后直接部署到真实机器人上 将VLM输出的可执行指令转换为固定的速度指令，例如将{前进，向左转，向右转，停止}转换为{0.5 m /s，π/6 rad/s， −π/6 rad/s ，0}并执行相应时间 采用PPO算法训练控制策略，了解PPO算法可参考我的强化学习笔记。Critic的观察空间包含当前时间步 t 的本体感觉和速度指令，以及机器人周围的特权地形高度扫描，其中本体感觉数据包括机器人的线速度和角速度、方向、关节位置、关节速度以及之前的动作。Actor的观察空间排除了线速度，动作空间定义为期望的关节位置 机器人配备了一个安装在其头部底座的 LiDAR 传感器，用于检测现实中的透明物体 实验复现(评估部分) 环境配置 创建模型评估的虚拟环境 1 2 conda create -n navila-eval python=3.10 conda activate navila-eval # 后续pip安装均在该环境下进行 安装 Habitat-Sim and Lab(v0.1.7),参考VLA-CE设置 由于Habitat-Sim(0.1.7)只支持python3.6~3.9，在3.10环境下需要采用源码安装\n1 2 3 4 5 6 7 8 # 安装Habitat-Lab git clone --branch v0.1.7 https://github.com/facebookresearch/habitat-lab.git cd habitat-lab # installs both habitat and habitat_baselines python -m pip install -r requirements.txt python -m pip install -r habitat_baselines/rl/requirements.txt python -m pip install -r habitat_baselines/rl/ddppo/requirements.txt python setup.py develop --all 安装Habitat-sim(v0.1.7),参考官方源码安装指南\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 git clone https://github.com/facebookresearch/habitat-sim.git #（默认就是v0.1.7） cd habitat-sim git submodule update --init --recursive git checkout v0.1.7 git submodule update --init --recursive #注意切换分支后可能导致部分submodule无效 python -m pip install -r requirements.txt # 如果出现路径问题编译不成功，可能因为之前编译过了，进入到habitat-sim目录删除build(rm -rf build) python -m pip install cmake sudo apt-get update || true sudo apt-get install -y --no-install-recommends \\ libjpeg-dev libglm-dev libgl1-mesa-glx libegl1-mesa-dev mesa-utils xorg-dev freeglut3-dev # 可能出现安装libgl1-mesa-glx不成功，可以尝试单独安装以下两个依赖 # sudo apt-get install libgl1-mesa-dev # sudo apt-get install libegl1-mesa-dev python -m pip install --upgrade pybind11 # 注意，编译要采用headless模式 python setup.py install --headless --cmake-args=\u0026#34;-DCMAKE_POLICY_VERSION_MINIMUM=3.5 -DCMAKE_CXX_STANDARD=11\u0026#34; 编译时若遇到error: ‘uint16_t’ in namespace ‘std’ does not name a type; did you mean ‘wint_t’?报错,在编译时添加 cstdint 头文件：\n1 python setup.py install --headless --cmake-args=\u0026#34;-DCMAKE_POLICY_VERSION_MINIMUM=3.5 -DCMAKE_CXX_STANDARD=11 -DCMAKE_CXX_FLAGS=-include\\ cstdint\u0026#34; 解决 NumPy 兼容性问题\n1 2 cd Navila python evaluation/scripts/habitat_sim_autofix.py # replace habitat_sim/utils/common.py 安装VLN-CE依赖 1 python -m pip install -r evaluation/requirements.txt 安装VILA依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 安装 FlashAttention2 python -m pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.5.8/flash_attn-2.5.8+cu122torch2.3cxx11abiFALSE-cp310-cp310-linux_x86_64.whl # 安装 VILA (假设在项目根目录下) python -m pip install -e . python -m pip install -e \u0026#34;.[train]\u0026#34; python -m pip install -e \u0026#34;.[eval]\u0026#34; # 安装 HF 的 Transformers python -m pip install git+https://github.com/huggingface/transformers@v4.37.2 # 替换部分包以兼容 site_pkg_path=$(python -c \u0026#39;import site; print(site.getsitepackages()[0])\u0026#39;) cp -rv ./llava/train/transformers_replace/* $site_pkg_path/transformers/ cp -rv ./llava/train/deepspeed_replace/* $site_pkg_path/deepspeed/ 5.修复 WebDataset 版本以实现 VLN-CE 兼容性\n1 python -m pip install webdataset==0.1.103 数据集下载 参考VLA-CE下载R2R和RxR数据集，并解压到evaluation/data路径 下载Matterport3D数据集，可通过官网申请获取，也可参考mp3D 数据集 数据应具备如下结构：evaluation/data\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 data/datasets ├─ RxR_VLNCE_v0 | ├─ train | | ├─ train_guide.json.gz | | ├─ ... | ├─ val_unseen | | ├─ val_unseen_guide.json.gz | | ├─ ... | ├─ ... ├─ R2R_VLNCE_v1-3_preprocessed | ├─ train | | ├─ train.json.gz | | ├─ ... | ├─ val_unseen | | ├─ val_unseen.json.gz | | ├─ ... data/scene_datasets ├─ mp3d | ├─ 17DRP5sb8fy | | ├─ 17DRP5sb8fy.glb | | ├─ ... | ├─ ... 评估运行 下载checkpoint 从a8cheng/navila-llama3-8b-8f下载预训练模型，并解压到evaluation/models/navila-llama3-8b-8f路径下,可通过以下命令下载：\n1 2 # 安装 huggingface_hub python -m pip install huggingface_hub 创建下载脚本download_huggingface.py并运行,脚本内容如下：\n1 2 3 4 5 6 7 8 9 10 11 from huggingface_hub import snapshot_download local_dir = snapshot_download( repo_id=\u0026#34;a8cheng/navila-llama3-8b-8f\u0026#34;, local_dir=\u0026#34;~/NaVILA/navila-llama3-8b-8f\u0026#34;, cache_dir=\u0026#34;~/NaVILA/navila-llama3-8b-8f/cache\u0026#34;, # 改成自己的项目路径 token=\u0026#34;hf_******\u0026#34;, # 这里填写你的 HuggingFace 访问token endpoint=\u0026#34;https://hf-mirror.com\u0026#34; # 如果需要走镜像 ) print(\u0026#34;模型下载到本地路径:\u0026#34;, local_dir) 在r2r上运行评估 1 2 3 4 5 6 7 8 9 10 11 # bash scripts/eval/r2r.sh CKPT_PATH NUM_CHUNKS CHUNK_START_IDX \u0026#34;GPU_IDS\u0026#34; # 单显卡 bash scripts/eval/r2r.sh /data/code/seu004/czd/NaVILA/navila-llama3-8b-8f 1 0 \u0026#34;0\u0026#34; # 多显卡 bash scripts/eval/r2r.sh /data/code/seu004/czd/NaVILA/navila-llama3-8b-8f 4 0 \u0026#34;2,3,4,5\u0026#34; # 检查所有Python评估进程 ps aux | grep \u0026#34;run.py.*navila\u0026#34; # 停止当前评估 pkill -9 -f \u0026#34;run.py.*navila\u0026#34; # 完成评估后汇总并查看得分 python scripts/eval_jsons.py ./eval_out/navila-llama3-8b-8f/VLN-CE-v1/val_unseen NUM_CHUNKS Debug 记录项目复现过程中遇到的一些问题\n服务器网络问题\n复现该项目时还是初次使用服务器，服务器由于没有图形化界面，一些仿真没办法实时显示，且服务器访问国外的网站速度较慢，不像自己电脑那样可以直接搭梯子访问。不过可以通过让服务器端走本地代理的方式来解决： 在本地电脑输入以下命令: 1 2 # 本地端口号7897,需要查看自己的clash等代理软件的端口号,填写其他参数记得删去占位符\u0026lt;\u0026gt; ssh -vvv -N -R 7897:localhost:7897 -p \u0026lt;远程服务器端口号\u0026gt; \u0026lt;username\u0026gt;@\u0026lt;server_ip\u0026gt; 在服务器上设置环境变量 1 2 3 # 只在当前终端生效,将其写入~/.bashrc文件可以永久生效，但我没有那个权限 export http_proxy=\u0026#34;http://localhost:7897\u0026#34; export https_proxy=\u0026#34;http://localhost:7897\u0026#34; 这样服务器就可以访问外网了，克隆github项目、下载hugging_face模型等都可以顺利进行。\nMatterport3D数据集加载问题\nmp3d数据及下载比较麻烦，使用官方给的脚本不知道为什么只会下载scans文件夹，这里面一般是深度、RGB图片等原始数据,评估过程其实是不需要的，真正需要的是task文件夹下的文件，但即使我使用\u0026ndash;task habitat后缀仍然没法下载task相关文件，目前没找到解决办法，我是直接去找师兄要了数据集，也可以去咸鱼上买现成的。\n最后的场景文件夹下应包括.glb等格式的文件。不同的场景有不同的ID，理论上评估预训练模型需要许多场景，但我实测先装一个ID为zsNo4HB9uLZ的场景就可以跑通评测，过程中有的episode发现没有的场景会直接跳过，后续可以慢慢补充其他场景再进行评估。 实验结果 运行r2r.sh脚本后，终端会实时可视化VLM的action指令 并会在valuation/eval_out/navila-llama3-8b-8f/VLN-CE-v1/val_unseen/videos路径下生成大量评估视频，视频左下方为导航指令，视频名称中的spl是导航中常用的评估指标，基准值为1/0代表是否成功，再乘上一个最短路径与实际路径比值。\n每个视频是一个episode，会选取一个场景进行评估，解压R2R数据集下的val_unseen.json.gz文件后可以看到episodes总共有1838个，8张显卡大概要跑2～3小时，如果不查看最终分数的话不跑完也可以。 其中一个 spl=1 的episode如下：\n","date":"2025-12-24T12:39:23+08:00","permalink":"https://caibb16.github.io/p/navila%E5%A4%8D%E7%8E%B0%E7%AC%94%E8%AE%B0/","title":"Navila复现笔记"},{"content":"什么是强化学习 强化学习（Reinforcement Learning，RL）是一种机器学习范式，旨在训练智能体通过与环境交互来学习最佳行为策略，以最大化累积奖励。与监督学习不同，强化学习没有明确的输入输出对，而是通过试错和奖励信号来指导学习过程。\n强化学习的基本概念 智能体（Agent）：执行动作以与环境交互的实体。 环境（Environment）：智能体所处的外部系统，智能体通过与环境交互来获取状态和奖励。 状态（State）：环境在某一时刻的描述，智能体根据状态做出决策。 动作（Action）：智能体在特定状态下可以执行的操作。 奖励（Reward）：智能体执行动作后从环境中获得的反馈信号，用于评估动作的好坏。 策略（Policy）：智能体在给定状态下选择动作的规则或函数。 价值函数（Value Function）：评估在某一状态下，智能体未来可能获得的累积奖励。 马尔可夫决策过程 强化学习通常建模为马尔可夫决策过程（Markov Decision Process，MDP），包括状态空间、动作空间、转移概率和奖励函数。MDP假设未来状态仅依赖于当前状态和动作，而与过去状态无关。\nPPO算法简介 Proximal Policy Optimization（PPO）是一种常用的强化学习算法，属于策略梯度方法。PPO通过限制策略更新的幅度，确保新策略不会偏离旧策略过远，从而提高训练的稳定性和效率。PPO通常使用剪切概率比（clipped probability ratio）来限制策略更新。\n基本架构 策略网络（Policy Network）：用于输出在给定状态下选择各个动作的概率分布。 价值网络（Value Network）：用于估计在给定状态下的价值函数。 训练过程 采样数据：智能体与环境交互，策略网络根据当前状态 s 和自身策略，选择并执行动作 a，收集状态、动作、奖励和下一个状态的数据。 计算优势函数：使用价值网络估计状态的价值，并计算优势函数以评估动作的好坏。优势用于衡量在给定状态下选择某个动作相对于平均水平的好处，其计算方法通常是用动作价值函数减去状态价值函数。公式如下： A(s, a) = Q(s, a) - V(s) 其中， A(s, a)是优势函数，Q(s, a)表示在状态 s 下采取动作 a 随后继续遵循策略π的价值，V(s) 表示在状态 s 下遵循策略π的价值。 更新策略网络：利用优势函数来更新自己的策略网络，使自己更倾向于选择能获得高评分的动作。同时使用剪切概率比限制策略更新的幅度，确保新策略不会偏离旧策略过远。 更新价值网络：使用TD误差优化价值网络参数，TD误差可以衡量价值网络预测值与实际回报之间的差异。 ","date":"2025-12-21T14:49:14+08:00","permalink":"https://caibb16.github.io/p/reinforcement-learning/","title":"Reinforcement Learning"},{"content":" 记录常用 Linux 命令，偏\u0026quot;日常使用备忘\u0026quot;。\n文件与目录操作 查看与切换目录 1 2 3 4 5 6 7 8 9 10 pwd # 显示当前目录 ls # 列出文件 ls -l # 详细列表 ls -a # 显示隐藏文件 ls -lh # 人类可读的文件大小 cd /path/to/dir # 切换到指定目录 cd ~ # 回到家目录 cd - # 回到上一次所在目录 cd .. # 回到上级目录 创建与删除 1 2 3 4 5 6 7 8 9 mkdir mydir # 创建目录 mkdir -p dir1/dir2/dir3 # 递归创建多级目录 touch file.txt # 创建空文件或更新时间戳 rm file.txt # 删除文件 rm -r mydir # 递归删除目录 rm -rf mydir # 强制递归删除（危险！） rmdir emptydir # 删除空目录 复制与移动 1 2 3 4 5 6 7 cp file1.txt file2.txt # 复制文件 cp -r dir1 dir2 # 递归复制目录 cp -v source dest # 显示复制过程 mv oldname.txt newname.txt # 重命名文件 mv file.txt /path/to/dest/ # 移动文件 mv -i file.txt dest/ # 交互式移动（覆盖前询问） 查看文件内容 1 2 3 4 5 6 7 cat file.txt # 显示全部内容 less file.txt # 分页查看（q 退出） more file.txt # 分页查看（空格翻页） head file.txt # 显示前10行 head -n 20 file.txt # 显示前20行 tail file.txt # 显示后10行 tail -f log.txt # 实时跟踪文件更新（日志） 软件安装 1 2 3 4 sudo apt update # 更新软件包列表 sudo apt install package_name # 安装软件包 sudo apt remove package_name # 卸载软件包 sudo dpkg -i package.deb # 安装 .deb 包 文件搜索 1 2 3 4 5 6 7 8 9 find . -name \u0026#34;*.txt\u0026#34; # 在当前目录查找 txt 文件 find /path -type f -name \u0026#34;file\u0026#34; # 查找文件 find /path -type d -name \u0026#34;dir\u0026#34; # 查找目录 find . -mtime -7 # 查找7天内修改的文件 locate filename # 快速定位文件（需先 updatedb） which python # 查找命令所在路径 whereis ls # 查找命令、源码、手册位置 文本处理 grep（搜索文本） 1 2 3 4 5 6 grep \u0026#34;keyword\u0026#34; file.txt # 搜索关键字 grep -r \u0026#34;keyword\u0026#34; /path # 递归搜索目录 grep -i \u0026#34;keyword\u0026#34; file.txt # 忽略大小写 grep -n \u0026#34;keyword\u0026#34; file.txt # 显示行号 grep -v \u0026#34;keyword\u0026#34; file.txt # 反向匹配（排除） grep -E \u0026#34;regex\u0026#34; file.txt # 使用正则表达式 权限管理 1 2 3 4 5 6 7 8 9 chmod 755 file.sh # 修改权限（rwxr-xr-x） chmod +x script.sh # 添加执行权限 chmod -R 755 dir # 递归修改目录权限 chown user file.txt # 修改文件所有者 chown user:group file # 同时修改所有者和组 chown -R user dir # 递归修改目录所有者 chgrp group file.txt # 修改文件所属组 权限数字说明 4 = 读（r） 2 = 写（w） 1 = 执行（x） 755 = rwxr-xr-x（所有者全权限，组和其他人只读执行） 644 = rw-r\u0026ndash;r\u0026ndash;（所有者读写，其他人只读） 压缩与解压 tar 1 2 3 4 5 6 7 8 tar -cvf archive.tar dir/ # 打包目录 tar -czvf archive.tar.gz dir/ # 打包并 gzip 压缩 tar -cjvf archive.tar.bz2 dir/ # 打包并 bzip2 压缩 tar -xvf archive.tar # 解包 tar -xzvf archive.tar.gz # 解压 gzip tar -xjvf archive.tar.bz2 # 解压 bzip2 tar -xzvf archive.tar.gz -C /path # 解压到指定目录 zip / unzip 1 2 3 4 5 zip archive.zip file1 file2 # 压缩文件 zip -r archive.zip dir/ # 压缩目录 unzip archive.zip # 解压 unzip archive.zip -d /path # 解压到指定目录 系统信息 1 2 3 4 5 6 7 8 9 10 11 12 13 uname -a # 显示系统信息 hostname # 显示主机名 whoami # 当前用户名 id # 显示用户和组ID uptime # 系统运行时间 date # 显示日期时间 df -h # 磁盘使用情况（人类可读） du -sh dir/ # 目录大小 du -h --max-depth=1 # 显示一级子目录大小 free -h # 内存使用情况 进程管理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ps aux # 显示所有进程 ps aux | grep python # 查找特定进程 top # 实时查看进程（q 退出） htop # 更友好的 top（需安装） kill PID # 终止进程（PID 是进程号） kill -9 PID # 强制终止 killall process_name # 按名称终止所有进程 bg # 将任务放到后台 fg # 将任务调到前台 jobs # 显示后台任务 nohup command \u0026amp; # 后台运行，不受终端关闭影响 网络相关 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ping google.com # 测试网络连通性 ping -c 4 google.com # ping 4次后停止 ifconfig # 查看网络接口（旧） ip addr # 查看网络接口（新） ip route # 查看路由表 netstat -tuln # 查看监听端口 ss -tuln # 现代版 netstat curl http://example.com # 获取网页内容 curl -O http://example.com/file # 下载文件 wget http://example.com/file # 下载文件 scp file.txt user@host:/path # 远程复制文件 ssh user@host # SSH 登录远程主机 用户管理 1 2 3 4 5 6 7 8 9 10 11 useradd username # 创建用户 passwd username # 设置密码 userdel username # 删除用户 userdel -r username # 删除用户及其家目录 su - username # 切换用户 sudo command # 以 root 权限执行 who # 显示当前登录用户 w # 显示登录用户及活动 last # 显示登录历史 包管理（Ubuntu/Debian） 1 2 3 4 5 6 7 8 sudo apt update # 更新软件包列表 sudo apt upgrade # 升级所有软件包 sudo apt install package_name # 安装软件包 sudo apt remove package_name # 卸载软件包 sudo apt autoremove # 清理不需要的依赖 apt search keyword # 搜索软件包 apt show package_name # 显示软件包信息 包管理（CentOS/RHEL） 1 2 3 4 5 6 sudo yum update # 更新软件包 sudo yum install package_name # 安装软件包 sudo yum remove package_name # 卸载软件包 yum search keyword # 搜索软件包 yum info package_name # 显示软件包信息 环境变量 1 2 3 4 5 6 7 8 9 echo $PATH # 显示 PATH 变量 echo $HOME # 显示家目录 export VAR=\u0026#34;value\u0026#34; # 设置临时环境变量 export PATH=$PATH:/new/path # 添加到 PATH # 永久设置：编辑 ~/.bashrc 或 ~/.zshrc vim ~/.bashrc source ~/.bashrc # 重新加载配置 其他实用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 history # 显示命令历史 history | grep keyword # 搜索命令历史 !! # 执行上一条命令 !n # 执行第 n 条历史命令 clear # 清空屏幕（或 Ctrl+L） alias ll=\u0026#39;ls -la\u0026#39; # 创建命令别名 unalias ll # 删除别名 man command # 查看命令手册 command --help # 查看命令帮助 ln -s /path/to/file link_name # 创建符号链接（软链接） ln /path/to/file link_name # 创建硬链接 后续可继续补充更多高级命令（如 systemctl、cron、iptables 等）。\n","date":"2025-12-10T14:28:59+08:00","permalink":"https://caibb16.github.io/p/linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5/","title":"Linux 常用命令速查"},{"content":" 记录常用 PyTorch 张量操作命令，偏\u0026quot;查表备忘\u0026quot;。\n环境与基础 1 2 3 4 5 6 7 8 9 10 import torch # 查看版本 print(torch.__version__) # 判断是否有 GPU torch.cuda.is_available() # 当前 GPU 数量 torch.cuda.device_count() 1. 张量创建 1.1 从 Python 数据创建 1 2 3 4 x = torch.tensor([1, 2, 3]) # 1D x = torch.tensor([[1., 2.], [3., 4.]]) # 2D，浮点 x = torch.FloatTensor([1, 2, 3]) # 指定类型 x = torch.LongTensor([1, 2, 3]) # int64 1.2 常见初始化 1 2 3 4 5 6 7 torch.zeros(3, 4) # 全 0 torch.ones(2, 3) # 全 1 torch.full((2, 3), 7) # 全 7 torch.eye(3) # 单位矩阵 torch.arange(0, 10, 2) # [0, 2, 4, 6, 8] torch.linspace(0, 1, 5) # [0., 0.25, 0.5, 0.75, 1.] 1.3 随机张量 1 2 3 torch.rand(2, 3) # [0, 1) 均匀分布 torch.randn(2, 3) # N(0, 1) 正态分布 torch.randint(0, 10, (2, 3)) # [0, 10) 整数 1.4 与已有张量同形状 1 2 3 4 a = torch.randn(2, 3) torch.zeros_like(a) torch.ones_like(a) torch.rand_like(a) 2. 张量属性 1 2 3 4 5 6 7 x = torch.randn(2, 3, 4) x.shape # 或 x.size() x.ndim # 维度数 x.dtype # 数据类型 x.device # 设备 (cpu / cuda:0) x.numel() # 元素总数 3. 设备与类型转换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 x = torch.randn(3, 4) # 类型 x.float() # 转 float32 x.double() # 转 float64 x.long() # 转 int64 x.int() # 转 int32 # 设备 x_cuda = x.to(\u0026#39;cuda\u0026#39;) # 或 .cuda() x_cpu = x_cuda.to(\u0026#39;cpu\u0026#39;) # 或 .cpu() # 拷贝到同设备同类型 y = torch.zeros_like(x) # 形状/类型一致 4. 形状操作（view / reshape / squeeze 等） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 x = torch.randn(1, 3, 4) # 展平 x_flat = x.view(-1) # 展平为一维张量，-1表示自动计算这个维度的大小 # 改变形状 y = x.view(2, 12) # 2 x 12 z = x.reshape(3, 8) # 3 x 8（更通用） # 插入维度 x_unsq = x.unsqueeze(0) # 在 dim=0 插一维: (1, 2, 3, 4) x_unsq = x.unsqueeze(2) # (2, 3, 1, 4) # 去掉大小为1的维度 x_sq = x_unsq.squeeze() # 去掉所有 =1 的维度 x_sq = x_unsq.squeeze(0) # 只去掉 dim=0 # 交换维度 x_perm = x.permute(0, 2, 1) # (2, 4, 3) # 扩展维度 x_exp = x.expand(2, -1, -1) # 维度变为 (2, 3, 4)，-1表示该维度不变 # 转置（2D 专用） m = torch.randn(3, 4) m_t = m.t() # (4, 3) 5. 基本算术运算 1 2 3 4 5 6 7 8 9 10 11 12 13 14 a = torch.randn(2, 3) b = torch.randn(2, 3) a + b a - b a * b # 逐元素乘 a / b torch.add(a, b) torch.mul(a, b) # 标量运算 a + 2 a * 10 5.1 矩阵运算 1 2 3 4 5 6 7 8 9 10 11 12 13 14 A = torch.randn(2, 3) B = torch.randn(3, 4) C = A @ B # 矩阵乘法 C = torch.matmul(A, B) # 批量矩阵乘法 X = torch.randn(10, 2, 3) Y = torch.randn(10, 3, 4) Z = torch.matmul(X, Y) # (10, 2, 4) # 转置 + 乘法 A_T = A.t() torch.mm(A, B) # 2D 矩阵乘 6. 维度上的聚合操作 1 2 3 4 5 6 7 8 9 10 11 12 x = torch.randn(2, 3, 4) x.sum() # 所有元素和（标量） x.sum(dim=0) # 在 dim=0 上求和 x.mean(dim=1) # 在 dim=1 上求均值 x.max() # 全局最大值 x.max(dim=1) # 返回 (values, indices) x.min(dim=2) x.prod(dim=0) # 连乘 # 保留维度 x.sum(dim=1, keepdim=True) # shape 中 dim=1 仍保留，大小为1 7. 索引与切片 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 x = torch.arange(0, 12).view(3, 4) # x: # [[0, 1, 2, 3], # [4, 5, 6, 7], # [8, 9,10,11]] x[0, 0] # 标量 x[1] # 第2行 x[:, 1] # 第2列 x[0:2, 1:3] # 行0~1, 列1~2 # 使用布尔索引 mask = x \u0026gt; 5 x[mask] # 高级索引 idx = torch.tensor([0, 2]) x[idx] # 选第 0、2 行 8. 拼接与分割 1 2 3 4 5 6 7 8 9 10 11 a = torch.randn(2, 3) b = torch.randn(2, 3) # 沿行拼接（行数相同，列加长） torch.cat([a, b], dim=0) # (4, 3) # 沿列拼接（列数相同，行加长） torch.cat([a, b], dim=1) # (2, 6) # 堆叠（新增一维） torch.stack([a, b], dim=0) # (2, 2, 3) 9. 广播（Broadcasting） 1 2 3 4 5 6 7 8 9 x = torch.randn(2, 3) b = torch.randn(3) # b 自动扩展为 (2, 3) y = x + b # 手动调整维度后广播 w = torch.randn(2, 1) # (2,1) -\u0026gt; (2,3) z = x + w 10. 自动求导基础（梯度相关） 1 2 3 4 5 6 7 8 9 x = torch.randn(3, 4, requires_grad=True) # 开启梯度 y = x * 2 + 1 loss = y.mean() loss.backward() # 反向传播 x.grad # ∂loss/∂x x.grad.zero_() # 清空梯度 11. 常用张量实用函数 1 2 3 4 5 6 7 8 9 10 x = torch.tensor([-1.0, 0.5, 2.0]) torch.clamp(x, min=0.0, max=1.0) # 截断 torch.abs(x) # 绝对值 torch.relu(x) # ReLU torch.argmax(x) # 最大值索引 torch.argmin(x) # 最小值索引 torch.topk(x, k=2) # 取前 k 大 12. 与 NumPy 互转 1 2 3 4 5 6 7 8 9 10 11 import numpy as np # Tensor -\u0026gt; NumPy x = torch.randn(3, 4) np_arr = x.numpy() # 注意：共享内存（在 CPU 上） # NumPy -\u0026gt; Tensor y = torch.from_numpy(np_arr) # 如果在 GPU 上，需要先转回 CPU x_cpu = x.to(\u0026#39;cpu\u0026#39;).numpy() 后续如果有更多 PyTorch 命令（如优化器、DataLoader、nn.Module 等），可以在本文下继续补充新章节。\n","date":"2025-12-08T16:18:37+08:00","permalink":"https://caibb16.github.io/p/pytorch-%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5/","title":"PyTorch 张量操作命令速查"},{"content":"基础配置 1 2 3 4 5 6 7 8 9 # 设置用户名和邮箱（全局） git config --global user.name \u0026#34;你的名字\u0026#34; git config --global user.email \u0026#34;你的邮箱\u0026#34; # 配置全局代理，端口设置为clash的端口 git config --global http.proxy http://127.0.0.1:7897 # 查看当前配置 git config --list 仓库初始化与克隆 1 2 3 4 5 6 7 8 # 在当前目录初始化仓库 git init # 克隆远程仓库 git clone https://github.com/username/repo.git # 克隆指定分支 git clone -b 分支名 https://github.com/username/repo.git 分支管理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 查看本地分支 git branch # 创建新分支 git branch dev # 切换分支 git checkout dev # 创建并切换到新分支 git checkout -b feature-x # 删除本地分支 git branch -d dev git branch -D dev # 强制删除 本地和远程操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 查看远程仓库 git remote -v # 添加远程仓库 git remote add origin # 暂存文件到暂存区 git add 文件名 # 提交更改到本地仓库 git commit -m \u0026#34;提交信息\u0026#34; # 撤销上一次的更改提交 git reset --soft HEAD^ # 推送到远程仓库 git push origin main # 拉取远程仓库最新代码 git pull origin main ","date":"2025-12-06T00:00:00Z","permalink":"https://caibb16.github.io/p/git%E5%91%BD%E4%BB%A4%E8%87%AA%E7%94%A8/","title":"git命令自用"},{"content":"前置准备 运行相关命令前需先安装对应功能包，如turtlebot3、slam_toolbox、cartographer、nav2等。\n若从源码编译安装，请确保已编译对应功能包。 编译命令如下：\n1 2 cd ~/colcon_ws colcon build --symlink-install --packages-select \u0026lt;package_name\u0026gt; source命令如下，可添加至~/.bashrc文件中：\n1 2 source ~/colcon_ws/install/setup.bash source /usr/share/gazebo/setup.sh 启动脚本，加载TurtleBot3及世界模型 1 ros2 launch turtlebot3_gazebo turtlebot3_world.launch.py 启动 slam_toolbox slam_toolbox 运行在线 SLAM ：\n1 ros2 launch slam_toolbox online_sync_launch.py 启动 cartographer cartographer建图：\n1 ros2 launch turtlebot3_cartographer cartographer.launch.py 运行 RViz2 可视化 SLAM（cartographer自带rviz，无需启动） 1 ros2 run rviz2 rviz2 键盘控制机器人运动 1 ros2 run turtlebot3_teleop teleop_keyboard 保存地图供nav2使用 1 ros2 run nav2_map_server map_saver_cli -f ~/map 启动nav2导航 1 ros2 launch turtlebot3_navigation2 navigation2.launch.py map:=$HOME/map.yaml ","date":"2025-12-06T00:00:00Z","permalink":"https://caibb16.github.io/p/turtlebot3_test/","title":"Turtlebot3_test"},{"content":"数据类型 基本数据类型：数据值存储在自己空间 整数类型：byte、short、int、long\n整数在计算机中以补码形式存在，最高位为符号位\nbyte 1字节\nshort 2字节\nint 4字节\nlong 8字节\n浮点类型：float、double\n字符类型：char\n布尔类型：boolean\n引用数据类型：数据值存储在堆中，自己空间存储地址值 类、接口、数组\n类型转换 小范围转大范围：高位补0，符号位扩展\n大范围转小范围：直接截取低位\nswitch语句 case穿透：执行case语句时，若未发现break，则顺序执行下一个case语句，直到发现break为止\nif和switch的各自应用场景：if一般用于对范围的判断，switch用于在有限个数据任选其一\n循环语句 for和while的对比 相同点：运行规则相同\n不同点：for循环一般用于知道循环次数或者循环范围，while循环一般用于不知道循环次数和范围，只知道循环的结束条件\ncontinue和break continue：结束本次循环，进入下一次循环 break：结束整个循环\n数组 静态初始化（指定初始化值） 数据类型[] 数组名 = {元素1, 元素2, 元素3\u0026hellip; }\n动态初始化（指定数组长度） 数据类型[] 数组名 = new 数据类型[数组长度];\n遍历数组 for(数据类型 变量名 : 数组名){ //使用变量名进行操作 }\n方法 方法的定义 我要干什么？——方法体 我需要什么？——形参 方法的基本内存原理 栈：方法调用时进栈，执行结束时出栈（先进后出）\n堆：创建对象（new）时进堆，存储引用数据类型的值\n基本数据类型和引用数据类型的存储 基本数据类型：数据值存储在自己的空间中（传递时传递数据）\n引用数据类型：数据值存储在堆中，自己空间中存储的是地址值（传递时传递地址）\n二维数组 初始化 数据类型[ ][ ] 数组名 = new 数据类型[行数][列数];\n数据类型[ ][ ] 数组名 = { {元素1, 元素2}, {元素3, 元素4} }\n遍历 外循环：遍历二维数组获取每一个一维数组 （数组名[ ]获取一维数组地址）\n内循环：遍历一维数组获取每一个元素 （数组名[ ][ ]同时获取一维数组地址和元素）\n面向对象 类和对象的关系 类是对象的模板，对象是类的具体体现\n成员变量和局部变量 成员变量：定义在类中，方法外，可以被类中的所有方法使用，默认初始化值\n局部变量：定义在方法中，只能被该方法使用，使用前必须初始化\n构造方法 方法名和类名相同 没有返回值类型 用于创建对象并初始化对象成员变量 方法重载 在同一个类中，允许存在一个以上的同名方法，只要它们的参数个数或参数类型不同即可\n就近原则和this关键字 就近原则：在方法中使用变量时，优先使用局部变量，如果没有则使用成员变量\nthis关键字的两种用法：\n表示当前对象的引用，指向当前对象本身 在构造方法中，this(形参列表)表示调用本类中的另一个构造方法 this的内存原理：this存储在栈中，指向堆中的当前对象，代表方法调用者的地址值\nJavaBean类（描述某类事物） 类是公共的（public） 有一个无参的公共构造方法 成员变量私有化（private） 对象的内存解析 栈：存储局部变量和方法调用\n堆：存储对象实例和数组实例，对象和数组的地址值存储在栈中\n方法区：存储类信息、常量、静态变量、方法字节码\nstatic关键字 静态变量 特点：被类的所有对象共享，随着类的加载而加载，优先于对象存在\n调用方式：类名.静态变量名 或 对象名.静态变量名\n静态方法 特点：多用在测试类和工具类中\n调用方式：类名.静态方法名 或 对象名.静态方法名\n静态方法中不能使用非静态的成员变量和成员方法，非静态方法二者都可以使用，因为静态方法优先于对象存在，而非静态的成员变量和成员方法依赖于对象存在\n工具类 提供静态方法，方便调用 构造方法私有化，避免创建对象 集合 ArrayList 动态数组，长度可变 存储有序的、可重复的数据 底层使用Object[]数组存储数据 继承 继承的基本概念 子类继承父类，子类拥有父类的属性和方法，可以访问父类的非私有成员 继承方法：使用extends关键字实现继承 继承特点：单继承、多层继承 单继承：Java中一个类只能有一个直接父类\n多层继承：子类继承父类，父类继承祖父类\nObject类：所有类都继承Object类\n继承中成员变量访问特点： 就进原则：子类对象访问成员变量时，优先访问局部变量，再访问子类自己的成员变量，再查找父类的成员变量，直到Object类为止，整个是一个向上的查找过程\nsuper关键字 表示父类对象的引用，指向父类对象本身\n在子类构造方法中，super(形参列表)表示调用父类的构造方法\nsuper.成员变量名：访问父类的成员变量\nsuper.成员方法名(实参列表)：访问父类的成员方法\n方法重写（Override） 子类继承父类后，可以对父类的方法进行重新定义和实现 重写方法的方法名、参数列表、返回值类型必须和父类被重写的方法相同 重写方法的访问权限不能小于父类被重写的方法的访问权限 父类被重写的方法不能是private、final、static修饰的 重写方法中可以调用父类被重写的方法，使用super关键字实现 多态 定义：父类引用指向子类对象\n使用：\n创建对象时，使用父类创建子类对象；\n定义方法时，形参使用父类类型，可以传入所有子类对象\n特点：\n多态只能发生在继承关系中\n多态只能调用子类重写父类的方法，不能调用子类特有的方法\n多态的前提是有继承关系和方法重写\n多态的体现：方法调用时，编译看左边，运行看右边;变量访问时，编译运行都看左边\n包 包的作用：用于对类进行分类管理，避免类名冲突\n包的声明：package 包名; 声明在类的第一行\n包的导入：import 包名.类名; 或 import 包名.*;*表示导入包中所有类\n使用其他类的规则：\n使用同一个包中的类，不需要导包 使用java.lang包中的类，不需要导包 其他情况都需要导包 使用两个包中的同名类，需要使用类的全限定名（包名.类名） final关键字 final修饰变量 基本数据类型：变量值不可改变 引用数据类型：引用地址不可改变，但对象的内容可以改变 final修饰方法 表示该方法不能被重写\nfinal修饰类 表示该类不能被继承\n静态代码块 使用static关键字修饰，随着类的加载而执行，并且只执行一次\n作用：用于初始化类的信息\n抽象类和抽象方法 抽象方法 父类中的抽象方法，提取子类的共性，没有方法体，用于被子类重写\n抽象类 抽象类不能实例化 继承抽象类的子类必须重写父类中的所有抽象方法，除非子类也是抽象类 抽象类可以有构造方法，用于子类创建对象时调用父类构造方法 作用：强制让子类按照某种格式重写 接口 接口的定义 使用interface关键字定义 接口中只能定义常量和抽象方法 接口的作用 规范类的行为 实现多继承，接口可以被多个子类实现 接口中的成员 成员变量：只能是常量，默认修饰符public static final 成员方法：只能是抽象方法，默认修饰符public abstract 接口的实现 使用implements关键字实现接口 格式：class 类名 implements 接口名1, 接口名2\u0026hellip;{} 实现接口的类必须重写接口中的所有抽象方法，除非该类是抽象类 接口和类之间的关系 类和类的关系：继承关系，只能单继承，不能多继承 类和接口的关系：实现关系，可以单实现，也可以多实现，可以在继承一个类的同时实现多个接口 接口和接口的关系：继承关系，可以单继承，也可以多继承 接口中新增的方法 默认方法 使用default关键字修饰，可以有方法体，实现类不强制重写 实现类可以重写接口中的默认方法，需要去掉default关键字 静态方法 使用static关键字修饰，可以有方法体，实现类不能重写 只能通过接口名调用接口中的静态方法 私有方法（Java 9及以上版本） 使用private关键字修饰 只能在接口内部使用，不能被实现类使用 内部类 成员内部类 创建内部类对象： 外部类名.内部类名 对象名 = new 外部类名().new 内部类名(); 在外部类的成员方法中创建内部类对象，外界通过外部类对象调用该方法获取内部类对象 内部类方法访问 访问内部类成员：this.成员变量名 或 成员变量名 访问外部类成员：外部类名.this.成员变量名 静态内部类 创建静态内部类对象 外部类名.内部类名 对象名 = new 外部类名.内部类名();\n静态内部类方法访问 访问静态方法：外部类名.内部类名.静态方法名(); 访问非静态方法：创建对象后，通过对象调用; 匿名内部类 定义：没有类名的内部类，必须继承一个类或实现一个接口，继承类或实现接口的同时创建对象 作用：简化代码编写 格式：new 父类名或接口名(){重写父类或接口的方法}; 单列集合 collection顶层接口 是单列集合的顶层接口，所有方法被list和set接口继承 常用方法：add()、remove()、clear()、size()、isEmpty()、contains()、toArray() List接口 有序、可重复的集合 常用实现类：ArrayList、LinkedList、Vector 常用方法：add(index, element)、get(index)、set(index, element)、remove(index)、indexOf(element)、lastIndexOf(element)、subList(fromIndex, toIndex) Set接口 无序、不可重复的集合 常用实现类：HashSet、LinkedHashSet、TreeSet HashSet：基于哈希表实现，存储元素无序 LinkedHashSet：基于哈希表和链表实现，存储元素有序 TreeSet：基于红黑树实现，存储元素有序 集合遍历 迭代器遍历 用于遍历集合元素 获取迭代器对象：Iterator iterator = 集合对象.iterator(); 常用方法：hasNext()、next()、remove()\nhasNext() 判断当前指针是否有元素，next() 获取当前指向的元素并移动指针，remove() 删除当前元素 增强for遍历 格式：for(数据类型 变量名 : 集合对象){ //使用变量名进行操作 } 适用于所有实现了Iterable接口的集合类 lamda表达式遍历 格式：集合对象.forEach(变量名 -\u0026gt; { //使用变量名进行操作 }); 简化代码编写，提高可读性 数据结构 栈 先进后出（LIFO）的数据结构 主要操作：push()入栈，pop()出栈，peek()查看栈顶元素 队列 先进先出（FIFO）的数据结构 主要操作：offer()入队，poll()出队，peek()查看队头元素 数组 由连续的内存空间组成的线性数据结构 每个元素通过索引访问，查询操作高效，插入和删除操作较慢 链表 由节点组成的线性数据结构，每个节点是独立的对象，在内存中不连续 每个节点包含数据值和下一个节点的地址 特点：插入和删除操作高效，查询操作较慢 泛型 集合中使用泛型 定义：在集合类中使用泛型，可以指定集合中存储元素的类型 格式：集合类\u0026lt;数据类型\u0026gt; 对象名 = new 集合类\u0026lt;\u0026gt;(); 细节： 泛型只能是引用数据类型，不能是基本数据类型 指定泛型的类型后，传递数据时可以传入该类型及其子类类型对象 如果不写泛型，默认类型为Object 泛型类 定义：在类定义时使用泛型，可以指定类中成员变量和方法的参数类型 格式： 定义类时：class 类名{ //类体 }，E表示不确定的类型 创建对象时：类名\u0026lt;数据类型\u0026gt; 对象名 = new 类名\u0026lt;\u0026gt;(); 泛型方法 定义：在方法定义时使用泛型，可以指定方法的参数类型和返回值类型 格式： 定义方法时： 返回值类型 方法名(E 参数名){ //方法体 } 调用方法时：对象名.方法名(实参); 泛型接口 定义：在接口定义时使用泛型，可以指定接口中方法的参数类型和返回值类型 格式： 定义接口时：interface 接口名{ //接口体 } 实现接口的两种方式： 实现类给出具体的类型：class 类名 implements 接口名\u0026lt;数据类型\u0026gt;{ //类体 } 实现类继续使用泛型：class 类名 implements 接口名{ //类体 } 泛型通配符 定义：在使用泛型时，可以使用通配符?表示不确定的类型\n上限通配符：? extends 父类类型，表示可以使用父类类型及其子类类型 下限通配符：? super 子类类型，表示可以使用子类类型及其父类类型 无限制通配符：?，表示可以使用任何类型 数据结构（树） 二叉树 定义：每个节点最多有两个子节点的树形数据结构 特点：每个节点有一个左子节点和一个右子节点 遍历方式： 前序遍历：先访问根节点，再访问左子树，最后访问右子树 中序遍历：先访问左子树，再访问根节点，最后访问右子树 后序遍历：先访问左子树，再访问右子树，最后访问根节点 二叉搜索树 定义：一种特殊的二叉树，满足左子节点小于根节点，右子节点大于根节点的性质 特点：支持高效的查找、插入和删除操作 应用：常用于实现动态集合 平衡二叉树 定义：一种自平衡的二叉搜索树，保证任意节点的左右子树高度差不超过1 特点：通过旋转操作保持平衡 应用：常用于实现高效的查找、插入和删除操作 红黑树 定义：一种自平衡的二叉搜索树，每个节点有颜色属性（红色或黑色） 特点：通过颜色属性和旋转操作 应用：常用于实现关联数组和集合 Set系列集合 特点：无序、不可重复、无索引\nHashSet 底层数据结构：哈希表（数组+链表/红黑树） 特点：无序、不可重复、查询效率高 添加元素过程： 计算元素的哈希值，确定存储位置 如果位置为空，直接存储 如果位置不为空，使用equals()方法判断是否重复，重复则不添加，不重复则添加到链表或红黑树中 接口实现： 重写hashCode()和equals()方法（这两个方法属于Object类），确保元素唯一性; 不同对象只要属性值相同，hashCode()返回相同的哈希值，equals()返回true LinkedHashSet 底层数据结构：哈希表+双向链表（维护元素的插入顺序） 特点：有序、不可重复、无索引 接口实现：重写hashCode()和equals()方法，确保元素唯一性 TreeSet 底层数据结构：红黑树 特点：有序、不可重复、无索引 添加元素过程： 使用compareTo()或compare()方法比较元素大小，确定存储位置 按照大小顺序存储元素 接口实现： 默认排序：集合中的元素实现Comparable接口，重写compareTo()方法，指定排序规则 比较器排序：集合使用Comparator接口，重写compare()方法，指定排序规则 双列集合 Map接口 双列集合的顶层接口，存储键值对（key-value） 常用实现类：HashMap、LinkedHashMap、TreeMap 常用方法：put(key, value)、get(key)、remove(key)、containsKey(key)、containsValue(value)、keySet()、values()、entrySet() 遍历方法： keySet()把键存储到Set集合中，遍历Set集合获取键，再通过键获取值 EntrySet()把键值对存储到Set集合中，遍历Set集合用getKey()和getValue()方法获取每一个键值对，再通过键值对获取键和值 Lambda表达式遍历：map.forEach((key, value) -\u0026gt; { //使用key和value进行操作 }); HashMap 底层数据结构：哈希表（数组+链表/红黑树） 特点：无序、不可重复、无索引 添加键值对过程： 计算键的哈希值，确定存储位置 如果位置为空，直接存储键值对 如果位置不为空，使用equals()方法判断键是否重复，重复则覆盖，不重复则添加到链表或红黑树中 LinkedHashMap 底层数据结构：哈希表+双向链表（维护键值对的插入顺序） 特点：有序、不可重复、无索引 添加键值对过程: 计算键的哈希值，确定存储位置 如果位置为空，直接存储键值对，并在双向链表中维护插入顺序 如果位置不为空，使用equals()方法判断键是否重复，重复则覆盖，不重复则添加到链表或红黑树中，并在双向链表中维护插入顺序 TreeMap 底层数据结构：红黑树 特点：有序(对键进行排序)、不可重复、无索引 添加键值对过程： 使用compareTo()或compare()方法比较键的大小，确定存储位置 按照键的大小顺序存储键值对 不可变集合 一旦创建后，集合的内容不能被修改（添加、删除、修改元素）\n创建不可变集合的方法 list.of(E\u0026hellip; elements)：创建不可变的List集合 set.of(E\u0026hellip; elements)：创建不可变的Set集合，元素不能重复 map.of(K k1, V v1, K k2, V v2, \u0026hellip;)：创建不可变的Map集合，键值对数量上限为10 map.ofEntries(Map.Entry\u0026lt;? extends K, ? extends V\u0026gt;\u0026hellip; entries)：创建不可变的Map集合，键值对数量不限 Stream流 使用 collection集合 集合对象.stream()：获取集合的Stream流 map集合 需要先使用entrySet()将map转换为单列集合，再转换为Stream流 Arrays工具类 Arrays.stream(数组对象)：获取数组的Stream流 Stream接口 静态方法：of()、iterate()、generate()、concat() 方法引用 定义：方法引用是Lambda表达式的一种简化形式，用于直接引用已有的方法，当做函数式接口中抽象方法的方法体 lambda表达式格式：参数列表 -\u0026gt; 方法体 方法引用格式：类名或对象名::方法名 引用静态方法：类名::静态方法名 引用成员方法：对象名::成员方法名 引用构造方法：类名::new 异常 异常的分类 检查异常（编译时异常）：在编译阶段被检查的异常，必须处理，否则编译不通过，如IOException、SQLException 非检查异常（运行时异常）：在运行阶段被检查的异常，不强制处理，如NullPointerException、ArrayIndexOutOfBoundsException 异常的处理 try-catch语句 用在方法调用处，能让代码继续运行 try块：包含可能抛出异常的代码，当执行到异常时，跳转到对应的catch块处理异常，不再执行try块中后续代码 catch块：捕获并处理异常，可以有多个catch块处理不同类型的异常。如果catch没有捕获到异常，异常会继续向上抛出 throws关键字 写在方法定义处，表示该方法可能抛出的异常类型，调用该方法时必须处理异常(编译异常一定要加throws) 格式：返回值类型 方法名(参数列表) throws 异常类型1, 异常类型2\u0026hellip; throw关键字 写在方法体中，表示抛出一个异常对象 格式：throw new 异常类型(\u0026ldquo;异常信息\u0026rdquo;); 自定义异常 手动定义异常类，继承Exception类或RuntimeException类，重写构造方法 用于表示特定的异常情况，让报错信息更加见名知义 ","date":"2025-12-05T00:00:00Z","permalink":"https://caibb16.github.io/p/java_study/","title":"java_study"},{"content":"Markdown 语法说明 Markdown 是一种轻量级标记语言，广泛用于编写文档、博客、说明书等。它语法简洁，易于阅读和编写，可快速转换为 HTML 网页。\n标题 使用 # 号表示标题，支持六级标题：\n1 2 3 # 一级标题 ## 二级标题 ### 三级标题 段落 直接输入文本即可形成段落。段落之间用空行分隔。\n引用块 使用 \u0026gt; 表示引用内容：\n1 \u0026gt; 这是引用内容 列表 无序列表：使用 *、- 或 + 作为标记 1 2 * 项目一 * 项目二 有序列表：使用数字加点 1 2 1. 第一项 2. 第二项 支持嵌套列表 代码块 行内代码：用反引号包裹，如 print('Hello') 多行代码块：用三个反引号包裹 1 2 3 4 ``` import torch print(torch.__version__) ``` 表格 使用 | 和 - 创建表格：\n1 2 3 4 | 姓名 | 年龄 | | ---- | ---- | | 张三 | 27 | | 李四 | 23 | 链接与图片 链接：[描述](网址) 图片：![描述](图片地址) 强调 斜体：用一个星号或下划线包裹 粗体：用两个星号或下划线包裹 删除线：用两个波浪线包裹 其他元素 分割线：--- 或 *** 脚注：[^1]，在文档底部添加脚注内容 行内 HTML：可直接嵌入 HTML 标签 特殊格式：如 \u0026lt;kbd\u0026gt;Ctrl\u0026lt;/kbd\u0026gt;、\u0026lt;mark\u0026gt;高亮\u0026lt;/mark\u0026gt;、\u0026lt;sub\u0026gt;下标\u0026lt;/sub\u0026gt;、\u0026lt;sup\u0026gt;上标\u0026lt;/sup\u0026gt; 视频与多媒体 图片：![图片描述](图片地址) 视频：\u0026lt;video src=\u0026quot;xxx.mp4\u0026quot; controls width=\u0026quot;700\u0026quot;\u0026gt;\u0026lt;/video\u0026gt; 数学公式 支持 LaTeX 语法：\n行内公式：$公式$ 块级公式：$$公式$$ 多行公式：$$$公式$$$ 常用 LaTeX 命令：\n1 2 3 4 5 6 \\alpha, \\beta, \\gamma, \\delta, \\epsilon # 希腊字母 \\sum_{下标}^{上标}, \\prod_{下标}^{上标}, \\int_{下标}^{上标} # 求和、乘积、积分 \\frac{分子}{分母} # 分数 \\sqrt{表达式} # 平方根 \\sqrt[n]{表达式} # n 次根 \\begin{matrix} ... \\end{matrix} # 矩阵 Markdown 语法简单易学，适合快速编写结构化文档。更多高级用法可参考 Markdown 官方文档 。\n","date":"2019-03-11T00:00:00Z","image":"https://caibb16.github.io/p/markdown-%E8%AF%AD%E6%B3%95%E6%8C%87%E5%8D%97/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu_e95a4276bf860a84.jpg","permalink":"https://caibb16.github.io/p/markdown-%E8%AF%AD%E6%B3%95%E6%8C%87%E5%8D%97/","title":"Markdown 语法指南"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\nBlock math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$","date":"2019-03-08T00:00:00Z","permalink":"https://caibb16.github.io/p/math-typesetting/","title":"Math Typesetting"}]